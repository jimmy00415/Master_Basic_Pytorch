{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbvE3JG64+/RLl4mIf+nnx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Part A — Calculations (20 pts)\n","\n","### A1. [6 pts] 1D Convolution (Stride 1, No Padding)\n","\n","**Given**  \n","Input: \\(x=[2,\\,1,\\,2,\\,3,\\,1,\\,0]\\) (length \\(N=6\\))  \n","Kernel: \\(w=[1,\\,-1,\\,2]\\) (length \\(F=3\\))  \n","Stride \\(S=1\\), Padding \\(P=0\\)\n","\n","**Output length**\n","$$\n","L_{\\text{out}}=\\frac{N-F+2P}{S}+1=\\frac{6-3+0}{1}+1=\\mathbf{4}.\n","$$\n","\n","**Cross-correlation dot-products** (window \\(\\cdot\\) kernel):\n","$$[2,1,2]\\cdot[1,-1,2]=2-1+4=\\mathbf{5}$$\n","$$[1,2,3]\\cdot[1,-1,2]=1-2+6=\\mathbf{5}$$\n","$$[2,3,1]\\cdot[1,-1,2]=2-3+2=\\mathbf{1}$$\n","$$[3,1,0]\\cdot[1,-1,2]=3-1+0=\\mathbf{2}$$\n","\n","**Answer:** \\(\\boxed{[5,\\,5,\\,1,\\,2]}\\)\n","\n","\n","### A2. [6 pts] 1D Convolution (Stride 2, No Padding)\n","\n","Same \\(x\\) and \\(w\\); now \\(S=2\\), \\(P=0\\).\n","\n","**Output length**\n","$$\n","L_{\\text{out}}=\\left\\lfloor\\frac{6-3}{2}+1\\right\\rfloor\n","=\\left\\lfloor1.5+1\\right\\rfloor=\\mathbf{2}.\n","$$\n","\n","**Sampled starts:** \\(i=0,\\,2\\)\n","$$[2,1,2]\\cdot[1,-1,2]=\\mathbf{5}\\qquad\n","[2,3,1]\\cdot[1,-1,2]=\\mathbf{1}$$\n","\n","**Answer:** \\(\\boxed{[5,\\,1]}\\)\n","\n","\n","### A3. [8 pts] 2D Convolution (Stride 1, No Padding)\n","\n","**Input**\n","$$\n","X=\\begin{bmatrix}\n","1&2&0&1\\\\\n","0&1&3&2\\\\\n","2&1&0&1\\\\\n","1&0&2&3\n","\\end{bmatrix} \\quad (4\\times4)\n","$$\n","\n","**Kernel**\n","$$\n","K=\\begin{bmatrix}\n","1&-1\\\\\n","0&2\n","\\end{bmatrix} \\quad (2\\times2)\n","$$\n","\n","**Output size** (\\(S=1,\\,P=0\\))\n","$$\n","H_{\\text{out}}=W_{\\text{out}}=\\frac{4-2+0}{1}+1=3\n","$$\n","Final feature map: **\\(3\\times3\\)**.\n","\n","**Requested values (cross-correlation, no flip)**\n","\n","Top-left \\((0,0)\\): use \\(X[0{:}2,0{:}2]=\\begin{bmatrix}1&2\\\\0&1\\end{bmatrix}\\)\n","$$\n","1\\cdot1+2\\cdot(-1)+0\\cdot0+1\\cdot2=\\boxed{1}\n","$$\n","\n","Top-right \\((0,2)\\): use \\(X[0{:}2,2{:}4]=\\begin{bmatrix}0&1\\\\3&2\\end{bmatrix}\\)\n","$$\n","0\\cdot1+1\\cdot(-1)+3\\cdot0+2\\cdot2=\\boxed{3}\n","$$\n","\n","Bottom-left \\((2,0)\\): use \\(X[2{:}4,0{:}2]=\\begin{bmatrix}2&1\\\\1&0\\end{bmatrix}\\)\n","$$\n","2\\cdot1+1\\cdot(-1)+1\\cdot0+0\\cdot2=\\boxed{1}\n","$$\n","\n","**Final output size:** \\(\\boxed{3\\times3}\\).\n"],"metadata":{"id":"RGD1RiCnAIHP"}},{"cell_type":"markdown","source":["## Part B — Single-Layer CNNs (20 pts)\n","\n","### B1. [10 pts] Conv Layer\n","\n","**Network**\n","1) Input: \\((1, 1, 28, 28)\\)  \n","2) Conv: in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1\n","\n","#### Manual verification\n","For PyTorch `Conv2d` (dilation = 1), each spatial dim uses:\n","$$\n","H_{\\text{out}}=\\left\\lfloor \\frac{H + 2p - (k-1) - 1}{s} + 1 \\right\\rfloor,\\quad\n","W_{\\text{out}}=\\left\\lfloor \\frac{W + 2p - (k-1) - 1}{s} + 1 \\right\\rfloor.\n","$$\n","Here \\(H=W=28,\\;k=3,\\;s=1,\\;p=1\\):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}=\\left\\lfloor \\frac{28 + 2\\cdot 1 - (3-1) - 1}{1} + 1 \\right\\rfloor\n","= \\left\\lfloor 27 \\right\\rfloor + 1 = 28.\n","$$\n","\n","**Expected shape after conv:** \\(\\boxed{(1, 4, 28, 28)}\\). :contentReference[oaicite:1]{index=1}\n"],"metadata":{"id":"evLwOXiWENyp"}},{"cell_type":"code","source":["# B1: Conv layer (nn.Module), print input & output shapes\n","import torch\n","import torch.nn as nn\n","\n","class SingleConv(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n","\n","    def forward(self, x):\n","        print(\"B1 Input:\", x.shape)\n","        y = self.conv(x)\n","        print(\"B1 After Conv:\", y.shape)\n","        return y\n","\n","# Test\n","x = torch.randn(1, 1, 28, 28)\n","_ = SingleConv()(x)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtaUZYv4EPsl","executionInfo":{"status":"ok","timestamp":1759561994292,"user_tz":-480,"elapsed":7209,"user":{"displayName":"yiwei chen","userId":"17638001754908949321"}},"outputId":"20a69462-c072-434e-a74c-d2c02d29548b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["B1 Input: torch.Size([1, 1, 28, 28])\n","B1 After Conv: torch.Size([1, 4, 28, 28])\n"]}]},{"cell_type":"markdown","source":["### B2. [10 pts] Conv + MaxPool\n","\n","**Network**\n","1) Input: \\((1, 1, 32, 32)\\)  \n","2) Conv: \\(1 \\to 6\\), kernel=5, stride=1, padding=0  \n","3) Pool: MaxPool2d(kernel_size=2, stride=2)\n","\n","#### Manual verification\n","**After Conv** (dilation = 1):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}=\\left\\lfloor \\frac{32 + 2\\cdot 0 - (5-1) - 1}{1} + 1 \\right\\rfloor\n","= \\left\\lfloor 27 \\right\\rfloor + 1 = 28.\n","$$\n","So the tensor becomes \\((1, 6, 28, 28)\\). :contentReference[oaicite:2]{index=2}\n","\n","**After MaxPool2d** (kernel=2, stride=2, padding=0; dilation=1):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}=\\left\\lfloor \\frac{28 + 0 - (2-1) - 1}{2} + 1 \\right\\rfloor\n","= \\left\\lfloor \\frac{26}{2} + 1 \\right\\rfloor = 14.\n","$$\n","Final shape: \\(\\boxed{(1, 6, 14, 14)}\\). :contentReference[oaicite:3]{index=3}\n"],"metadata":{"id":"ZDsoXGj9EX-u"}},{"cell_type":"code","source":["# B2: Conv + MaxPool (nn.Module), print shapes after each layer\n","import torch\n","import torch.nn as nn\n","\n","class ConvMaxPoolNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        print(\"B2 Input:\", x.shape)\n","        x = self.conv(x)\n","        print(\"B2 After Conv:\", x.shape)\n","        x = self.pool(x)\n","        print(\"B2 After Pool:\", x.shape)\n","        return x\n","\n","# Test\n","x = torch.randn(1, 1, 32, 32)\n","_ = ConvMaxPoolNet()(x)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Anje8tbfEYOB","executionInfo":{"status":"ok","timestamp":1759562039395,"user_tz":-480,"elapsed":127,"user":{"displayName":"yiwei chen","userId":"17638001754908949321"}},"outputId":"fe2b80f9-4987-4d08-efbc-b9458dd88f63"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["B2 Input: torch.Size([1, 1, 32, 32])\n","B2 After Conv: torch.Size([1, 6, 28, 28])\n","B2 After Pool: torch.Size([1, 6, 14, 14])\n"]}]},{"cell_type":"markdown","source":["## Part C — Multi-Layer CNNs (20 pts)\n","\n","### C1. [10 pts] Two Conv Layers\n","\n","**Network**  \n","- Input: \\((1, 1, 32, 32)\\)  \n","- Conv1: \\(1 \\rightarrow 6\\), kernel \\(k=5\\), stride \\(s=1\\), padding \\(p=0\\)  \n","- Conv2: \\(6 \\rightarrow 16\\), kernel \\(k=5\\), stride \\(s=1\\), padding \\(p=0\\)\n","\n","**Manual size verification**  \n","For PyTorch `Conv2d` (with dilation \\(d=1\\)), each spatial dimension uses:\n","$$\n","H_{\\text{out}}\n","= \\left\\lfloor \\frac{H + 2p - (k-1) - 1}{s} + 1 \\right\\rfloor,\n","\\quad\n","W_{\\text{out}}\n","= \\left\\lfloor \\frac{W + 2p - (k-1) - 1}{s} + 1 \\right\\rfloor.\n","$$\n","\n","**After Conv1** (start \\(H=W=32\\), \\(k=5, s=1, p=0\\)):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}\n","= \\left\\lfloor \\frac{32 + 0 - (5-1) - 1}{1} + 1 \\right\\rfloor\n","= \\left\\lfloor 27 \\right\\rfloor + 1\n","= 28.\n","$$\n","Shape: \\(\\boxed{(1,\\,6,\\,28,\\,28)}\\).\n","\n","**After Conv2** (start \\(28\\times28\\), \\(k=5, s=1, p=0\\)):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}\n","= \\left\\lfloor \\frac{28 + 0 - (5-1) - 1}{1} + 1 \\right\\rfloor\n","= \\left\\lfloor 23 \\right\\rfloor + 1\n","= 24.\n","$$\n","Shape: \\(\\boxed{(1,\\,16,\\,24,\\,24)}\\).\n","\n","**Expected shapes:** after Conv1 → \\((1,6,28,28)\\); after Conv2 → \\((1,16,24,24)\\).\n","\n","---\n","\n","### C2. [10 pts] Conv + Pool + Linear\n","\n","**Network**  \n","- Input: \\((1, 1, 28, 28)\\)  \n","- Conv: \\(1 \\rightarrow 8\\), kernel \\(k=3\\), stride \\(s=1\\), padding \\(p=1\\)  \n","- Pool: `MaxPool2d(kernel_size=2, stride=2)`  \n","- Flatten  \n","- Linear: \\(\\text{in\\_features} \\rightarrow 10\\)\n","\n","**Manual size verification**\n","\n","**After Conv** (\\(H=W=28, k=3, s=1, p=1\\)):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}\n","= \\left\\lfloor \\frac{28 + 2\\cdot 1 - (3-1) - 1}{1} + 1 \\right\\rfloor\n","= \\left\\lfloor 27 \\right\\rfloor + 1\n","= 28.\n","$$\n","Shape: \\(\\boxed{(1,\\,8,\\,28,\\,28)}\\).\n","\n","**After MaxPool(2,2)** (pooling uses the same shape rule with \\(d=1\\)):\n","$$\n","H_{\\text{out}}=W_{\\text{out}}\n","= \\left\\lfloor \\frac{28 + 0 - (2-1) - 1}{2} + 1 \\right\\rfloor\n","= \\left\\lfloor \\frac{26}{2} + 1 \\right\\rfloor\n","= 14.\n","$$\n","Shape: \\(\\boxed{(1,\\,8,\\,14,\\,14)}\\).\n","\n","**Flatten → Linear in\\_features**\n","\\[\n","8 \\times 14 \\times 14 = \\boxed{1568}\n","\\]\n","So the classifier is `Linear(1568, 10)`.\n","\n","**Expected shapes:** after Conv → \\((1,8,28,28)\\); after Pool → \\((1,8,14,14)\\); after Flatten → \\((1,1568)\\); after Linear → \\((1,10)\\).\n","\n","\n"],"metadata":{"id":"XkRffHc8Ejyn"}},{"cell_type":"code","source":["# === C1. Two Conv Layers ===\n","import torch\n","import torch.nn as nn\n","\n","class TwoConvNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0)\n","        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        print(\"C1 Input:\", x.shape)           # (1, 1, 32, 32)\n","        x = self.conv1(x)\n","        print(\"C1 After Conv1:\", x.shape)     # (1, 6, 28, 28)\n","        x = self.conv2(x)\n","        print(\"C1 After Conv2:\", x.shape)     # (1, 16, 24, 24)\n","        return x\n","\n","# quick test\n","_ = TwoConvNet()(torch.randn(1, 1, 32, 32))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUSd1WXpFEGi","executionInfo":{"status":"ok","timestamp":1759562199304,"user_tz":-480,"elapsed":8,"user":{"displayName":"yiwei chen","userId":"17638001754908949321"}},"outputId":"fbf61c5f-2b71-4d85-aaf7-0649b05cafc1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["C1 Input: torch.Size([1, 1, 32, 32])\n","C1 After Conv1: torch.Size([1, 6, 28, 28])\n","C1 After Conv2: torch.Size([1, 16, 24, 24])\n"]}]},{"cell_type":"code","source":["# === C2. Conv + Pool + Flatten + Linear ===\n","import torch\n","import torch.nn as nn\n","\n","class ConvPoolLinearNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.flatten = nn.Flatten()           # flattens from dim 1 .. -1\n","        self.fc = nn.Linear(1568, 10)         # 8 * 14 * 14 = 1568\n","\n","    def forward(self, x):\n","        print(\"C2 Input:\", x.shape)           # (1, 1, 28, 28)\n","        x = self.conv(x)\n","        print(\"C2 After Conv:\", x.shape)      # (1, 8, 28, 28)\n","        x = self.pool(x)\n","        print(\"C2 After Pool:\", x.shape)      # (1, 8, 14, 14)\n","        x = self.flatten(x)\n","        print(\"C2 After Flatten:\", x.shape)   # (1, 1568)\n","        x = self.fc(x)\n","        print(\"C2 After Linear:\", x.shape)    # (1, 10)\n","        return x\n","\n","# quick test\n","_ = ConvPoolLinearNet()(torch.randn(1, 1, 28, 28))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBjtE0OTFIFS","executionInfo":{"status":"ok","timestamp":1759562213842,"user_tz":-480,"elapsed":6,"user":{"displayName":"yiwei chen","userId":"17638001754908949321"}},"outputId":"96ef7acc-b702-474e-b33d-1ac8cb14e6b8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["C2 Input: torch.Size([1, 1, 28, 28])\n","C2 After Conv: torch.Size([1, 8, 28, 28])\n","C2 After Pool: torch.Size([1, 8, 14, 14])\n","C2 After Flatten: torch.Size([1, 1568])\n","C2 After Linear: torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","source":["## Part D — Advanced Structures (40 pts)\n","\n","### D1 — CNN with Mixed Pooling (15 pts)\n","**Network**\n","- Input: (1, 1, 28, 28)\n","- Conv1: 1→8, k=3, s=1, p=1 → MaxPool(2,2)\n","- Conv2: 8→16, k=3, s=1, p=1 → AvgPool(2,2)\n","- Flatten → Linear: 16×7×7 → 10\n","\n","**Manual size checks** (per spatial dim; dilation d=1):\n","$$\n","H_{\\text{out}}=\\left\\lfloor \\frac{H+2p-(k-1)-1}{s}+1\\right\\rfloor\\quad(\\text{same for }W)\n","$$\n","- After Conv1: 28→28 → (1,8,28,28)\n","- MaxPool(2,2): 28→14 → (1,8,14,14)\n","- After Conv2: 14→14 → (1,16,14,14)\n","- AvgPool(2,2): 14→7 → (1,16,7,7)\n","- Flatten → Linear in_features = 16×7×7 = **784** → Linear(784, 10)\n","\n","**Linear params** = 784×10 + 10 = **7,850**.\n","\n","---\n","\n","### D2 — CNN with Strides (10 pts)\n","**Network**\n","- Input: (1, 1, 64, 64)\n","- Conv1: 1→8, k=3, s=2, p=1\n","- Conv2: 8→16, k=3, s=2, p=1\n","\n","**Manual check** (stride 2 halves H,W with k=3, p=1):\n","- 64 → 32 after Conv1\n","- 32 → 16 after Conv2\n","\n","---\n","\n","### D3 — Two-Branch CNN (15 pts)\n","**Network**\n","- Input: (1,1,32,32)\n","- Branch A: Conv 1→4 (k=3,p=1,s=1) → MaxPool(2,2) → (1,4,16,16)\n","- Branch B: Conv 1→4 (k=5,p=2,s=1) → AvgPool(2,2) → (1,4,16,16)\n","- Fusion: concatenate along channels: (1,8,16,16)\n","- Flatten → Linear: in_features = 8×16×16 = **2048** → Linear(2048, 10)\n"],"metadata":{"id":"g9VUS21yFpAp"}},{"cell_type":"code","source":["# Part D — PyTorch implementations with shape prints\n","import torch\n","import torch.nn as nn\n","\n","# D1\n","class MixedPoolingNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 8, 3, 1, 1)\n","        self.maxp  = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n","        self.avgp  = nn.AvgPool2d(2, 2)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(16*7*7, 10)\n","\n","    def forward(self, x):\n","        print(\"D1 Input:\", x.shape)           # (1,1,28,28)\n","        x = self.conv1(x); print(\"D1 Conv1:\", x.shape)    # (1,8,28,28)\n","        x = self.maxp(x);  print(\"D1 MaxPool:\", x.shape)  # (1,8,14,14)\n","        x = self.conv2(x); print(\"D1 Conv2:\", x.shape)    # (1,16,14,14)\n","        x = self.avgp(x);  print(\"D1 AvgPool:\", x.shape)  # (1,16,7,7)\n","        x = self.flatten(x); print(\"D1 Flatten:\", x.shape) # (1,784)\n","        x = self.fc(x);    print(\"D1 Linear:\", x.shape)   # (1,10)\n","        return x\n","\n","# D2\n","class StrideCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 8, 3, 2, 1)  # 64->32\n","        self.conv2 = nn.Conv2d(8,16, 3, 2, 1)  # 32->16\n","    def forward(self, x):\n","        print(\"D2 Input:\", x.shape)            # (1,1,64,64)\n","        x = self.conv1(x); print(\"D2 Conv1:\", x.shape)    # (1,8,32,32)\n","        x = self.conv2(x); print(\"D2 Conv2:\", x.shape)    # (1,16,16,16)\n","        return x\n","\n","# D3\n","class TwoBranchCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Branch A\n","        self.convA = nn.Conv2d(1, 4, 3, 1, 1)\n","        self.maxpA = nn.MaxPool2d(2, 2)\n","        # Branch B\n","        self.convB = nn.Conv2d(1, 4, 5, 1, 2)\n","        self.avgpB = nn.AvgPool2d(2, 2)\n","        # Head\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(8*16*16, 10)  # 2048 -> 10\n","\n","    def forward(self, x):\n","        print(\"D3 Input:\", x.shape)           # (1,1,32,32)\n","        A = self.maxpA(self.convA(x)); print(\"D3 Branch A:\", A.shape)  # (1,4,16,16)\n","        B = self.avgpB(self.convB(x)); print(\"D3 Branch B:\", B.shape)  # (1,4,16,16)\n","        x = torch.cat([A,B], dim=1);  print(\"D3 Concat:\", x.shape)     # (1,8,16,16)\n","        x = self.flatten(x);          print(\"D3 Flatten:\", x.shape)    # (1,2048)\n","        x = self.fc(x);               print(\"D3 Linear:\", x.shape)     # (1,10)\n","        return x\n","\n","# quick sanity runs (comment out when submitting)\n","_ = MixedPoolingNet()(torch.randn(1,1,28,28))\n","_ = StrideCNN()(torch.randn(1,1,64,64))\n","_ = TwoBranchCNN()(torch.randn(1,1,32,32))\n","\n","# Linear param count for D1\n","mp = MixedPoolingNet()\n","print(\"D1 Linear params:\", mp.fc.weight.numel() + mp.fc.bias.numel())  # expect 7850\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqZK5b9AGoOK","executionInfo":{"status":"ok","timestamp":1759562607337,"user_tz":-480,"elapsed":34,"user":{"displayName":"yiwei chen","userId":"17638001754908949321"}},"outputId":"65b0c674-7805-4632-c10e-7892dff967fd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["D1 Input: torch.Size([1, 1, 28, 28])\n","D1 Conv1: torch.Size([1, 8, 28, 28])\n","D1 MaxPool: torch.Size([1, 8, 14, 14])\n","D1 Conv2: torch.Size([1, 16, 14, 14])\n","D1 AvgPool: torch.Size([1, 16, 7, 7])\n","D1 Flatten: torch.Size([1, 784])\n","D1 Linear: torch.Size([1, 10])\n","D2 Input: torch.Size([1, 1, 64, 64])\n","D2 Conv1: torch.Size([1, 8, 32, 32])\n","D2 Conv2: torch.Size([1, 16, 16, 16])\n","D3 Input: torch.Size([1, 1, 32, 32])\n","D3 Branch A: torch.Size([1, 4, 16, 16])\n","D3 Branch B: torch.Size([1, 4, 16, 16])\n","D3 Concat: torch.Size([1, 8, 16, 16])\n","D3 Flatten: torch.Size([1, 2048])\n","D3 Linear: torch.Size([1, 10])\n","D1 Linear params: 7850\n"]}]}]}