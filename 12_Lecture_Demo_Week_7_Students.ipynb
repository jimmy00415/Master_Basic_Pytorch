{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff60271e",
   "metadata": {},
   "source": [
    "### üßæ Code Cell 1: Move data to the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075a761",
   "metadata": {
    "id": "qANewq80B7JG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create tensor on CPU\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(x.device)   # cpu\n",
    "\n",
    "# Move tensor to GPU\n",
    "x_gpu = x.to(device)\n",
    "print(x_gpu.device)  # cuda:0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be580bbb",
   "metadata": {},
   "source": [
    "### üßæ Code Cell 2: Demonstrating a Device Mismatch Error\n",
    "This cell intentionally produces a device mismatch error to show what happens when tensors and models are placed on different devices (e.g., CPU vs GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a756b",
   "metadata": {
    "id": "5_3vL-GuC6jK"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ‚ö†Ô∏è Part 1: Trigger a Device Mismatch Error\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"‚úÖ CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a simple model and move it to GPU\n",
    "model = nn.Linear(10, 2).to(device)\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "\n",
    "# Create data still on CPU\n",
    "x = torch.randn(4, 10)\n",
    "print(\"Data device:\", x.device)\n",
    "\n",
    "# Try forward pass (üí• this will crash!)\n",
    "out = model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c645b8d",
   "metadata": {},
   "source": [
    "### üßæ Code Cell 3: What this cell does\n",
    "- **Device Placement**: Moves tensors/model to CPU/GPU as needed.\n",
    "- **Tips**: Inspect printed shapes/metrics to confirm expectations.\n",
    "- **Position**: This explanation corresponds to code cell #3 in the original flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0094ec",
   "metadata": {
    "id": "oXrfvAzfC7RA"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ‚úÖ Part 2: Fix the Device Mismatch Error\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed8e4f",
   "metadata": {},
   "source": [
    "### üßæ Code Cell 4: Demonstrating GPU Memory Explosion\n",
    "This cell shows how GPU memory usage can explode when tensors that require gradients are not properly detached or reused inside a loop.\n",
    "It intentionally creates a situation where new computation graphs are built at every iteration, causing memory to grow rapidly until the GPU runs out of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9127f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIQ2UuVSHSoS",
    "outputId": "2c6a3e1e-8a21-46d5-e37d-627fe2639918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA available: True\n",
      "Sat Oct 18 07:16:18 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "--- Trying to allocate a large tensor on GPU ---\n",
      "\n",
      "--- Memory info after error ---\n",
      "Allocated: 12809.54 MB, Reserved: 12821.99 MB\n",
      "\n",
      "--- Retrying with smaller tensor ---\n",
      "‚úÖ Success! Tensor shape: torch.Size([4000, 4000])\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Demonstration: CUDA Out of Memory (OOM) in PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"‚úÖ CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 1Ô∏è‚É£: Print GPU info\n",
    "!nvidia-smi\n",
    "\n",
    "# Step 2Ô∏è‚É£: Create a large random tensor\n",
    "try:\n",
    "    print(\"\\n--- Trying to allocate a large tensor on GPU ---\")\n",
    "    x = torch.randn(40000, 40000, device=device)  # This may trigger OOM\n",
    "    y = x @ x\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n‚ùå RuntimeError caught:\")\n",
    "    print(e)\n",
    "\n",
    "# Step 3Ô∏è‚É£: Check how much memory was used\n",
    "print(\"\\n--- Memory info after error ---\")\n",
    "allocated = torch.cuda.memory_allocated() / 1e6\n",
    "reserved = torch.cuda.memory_reserved() / 1e6\n",
    "print(f\"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB\")\n",
    "\n",
    "# Step 4Ô∏è‚É£: Fix by reducing the tensor size\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\n--- Retrying with smaller tensor ---\")\n",
    "x = torch.randn(4000, 4000, device=device)\n",
    "y = x @ x\n",
    "print(\"‚úÖ Success! Tensor shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa0b44",
   "metadata": {},
   "source": [
    "### üßæ Code Cell 5: Vanishing Gradient Demonstration\n",
    "\n",
    "This cell illustrates the vanishing gradient problem, where gradients become very small in the earlier layers of a deep network.\n",
    "The code builds a multi-layer model with activations like sigmoid or tanh, performs backpropagation, and measures gradient magnitudes across layers.\n",
    "You‚Äôll see that the first (input) layer has the smallest gradient, showing that signals fade as they travel backward through many layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b391b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sIAQov8X6lI",
    "outputId": "493e0ef0-22cd-476c-ab76-f4a9061cd8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VANISHING GRADIENT DEMO\n",
      "----------------------------------------\n",
      "Gradient in last layer (fc10): 0.8905013799667358\n",
      "Gradient in middle layer (fc5): 2.7121091989101842e-05\n",
      "Gradient in first layer (fc1): 1.3565953693728261e-08\n",
      "\n",
      "‚ö†Ô∏è Notice: Gradients get smaller in earlier layers!\n",
      "This is the vanishing gradient problem with sigmoid.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================\n",
    "# Example 1: Vanishing Gradient\n",
    "# ============================================\n",
    "\n",
    "print(\"VANISHING GRADIENT DEMO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Deep network with sigmoid activation\n",
    "class VanishingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 10 layers with sigmoid activation\n",
    "        self.fc1 = nn.Linear(1, 5)\n",
    "        self.fc2 = nn.Linear(5, 5)\n",
    "        self.fc3 = nn.Linear(5, 5)\n",
    "        self.fc4 = nn.Linear(5, 5)\n",
    "        self.fc5 = nn.Linear(5, 5)\n",
    "        self.fc6 = nn.Linear(5, 5)\n",
    "        self.fc7 = nn.Linear(5, 5)\n",
    "        self.fc8 = nn.Linear(5, 5)\n",
    "        self.fc9 = nn.Linear(5, 5)\n",
    "        self.fc10 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        x = torch.sigmoid(self.fc6(x))\n",
    "        x = torch.sigmoid(self.fc7(x))\n",
    "        x = torch.sigmoid(self.fc8(x))\n",
    "        x = torch.sigmoid(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return x\n",
    "\n",
    "# Create model and compute gradients\n",
    "model = VanishingNet()\n",
    "x = torch.tensor([[1.0]])\n",
    "y = torch.tensor([[0.5]])\n",
    "\n",
    "# Forward and backward pass\n",
    "output = model(x)\n",
    "loss = (output - y) ** 2\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "print(\"Gradient in last layer (fc10):\", model.fc10.weight.grad.abs().mean().item())\n",
    "print(\"Gradient in middle layer (fc5):\", model.fc5.weight.grad.abs().mean().item())\n",
    "print(\"Gradient in first layer (fc1):\", model.fc1.weight.grad.abs().mean().item())\n",
    "print(\"\\n‚ö†Ô∏è Notice: Gradients get smaller in earlier layers!\")\n",
    "print(\"This is the vanishing gradient problem with sigmoid.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
